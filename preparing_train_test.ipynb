{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0a5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2734643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "root_dir = r'C:\\Users\\Ramzan\\Documents\\Self Supervised Learning'\n",
    "images_dir = os.path.join(root_dir, 'dataset', 'flowers')\n",
    "data_dir_list = os.listdir(images_dir)\n",
    "print(data_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acef8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "labels_name = {'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc462ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the images of dataset daisy\n",
      "\n",
      "Read 764 images out of 764 from data dir daisy\n",
      "\n",
      "Loading the images of dataset dandelion\n",
      "\n",
      "Read 1052 images out of 1052 from data dir dandelion\n",
      "\n",
      "Loading the images of dataset rose\n",
      "\n",
      "Read 784 images out of 784 from data dir rose\n",
      "\n",
      "Loading the images of dataset sunflower\n",
      "\n",
      "Read 733 images out of 733 from data dir sunflower\n",
      "\n",
      "Loading the images of dataset tulip\n",
      "\n",
      "Read 984 images out of 984 from data dir tulip\n",
      "\n",
      "Completed reading all the image file and assigned labels accordingly\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=['FileName', 'Label', 'ClassName'])\n",
    "test_df = pd.DataFrame(columns=['FileName', 'Label', 'ClassName'])\n",
    "\n",
    "num_images_for_test = 60\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(os.path.join(images_dir, dataset))\n",
    "    print(f'Loading the images of dataset {dataset}\\n')\n",
    "    label = labels_name[dataset]\n",
    "    num_img_files  = len(img_list)\n",
    "    num_corrupted_files = 0\n",
    "    test_list_index = random.sample(range(1, num_img_files-1), num_images_for_test)\n",
    "\n",
    "    for i in range(num_img_files):\n",
    "        img_name = img_list[i]\n",
    "        img_filename = os.path.join(images_dir, dataset, img_name)\n",
    "        try:\n",
    "            input_img = cv2.imread(img_filename)\n",
    "            img_shape = input_img.shape\n",
    "            if i in test_list_index:\n",
    "                test_df = pd.concat([test_df, pd.DataFrame([{'FileName': img_filename, 'Label': label, 'ClassName': dataset}])], ignore_index = True)\n",
    "            else:\n",
    "                train_df = pd.concat([train_df, pd.DataFrame([{'FileName': img_filename, 'Label': label, 'ClassName': dataset}])], ignore_index = True)\n",
    "        except:\n",
    "            print(f'{img_filename} is corrupted\\n')\n",
    "            num_corrupted_files += 1\n",
    "    \n",
    "    print(f'Read {num_img_files - num_corrupted_files} images out of {num_img_files} from data dir {dataset}\\n')\n",
    "print('Completed reading all the image file and assigned labels accordingly')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb60b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train and test csv files are saved\n"
     ]
    }
   ],
   "source": [
    "dest_path = os.path.join('dataset', 'annotations')\n",
    "if not os.path.exists(dest_path):\n",
    "    os.mkdir(dest_path)\n",
    "\n",
    "train_df.to_csv(os.path.join(dest_path,'flower_recognition_train.csv'))\n",
    "test_df.to_csv(os.path.join(dest_path,'flower_recognition_test.csv'))\n",
    "print('The train and test csv files are saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
